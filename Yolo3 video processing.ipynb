{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Yolo3 video processing.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOgNyqUlmR0KghrVfRY0D0U"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"rjkllFpMeNwt","colab_type":"code","outputId":"f83610ea-c0c5-48ad-bc70-23d8f02c9469","executionInfo":{"status":"ok","timestamp":1589621777588,"user_tz":-180,"elapsed":5563,"user":{"displayName":"Volodymyr Todosiuk","photoUrl":"","userId":"17845359462101600766"}},"colab":{"base_uri":"https://localhost:8080/","height":134}},"source":["!git clone https://github.com/ultralytics/yolov3"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Cloning into 'yolov3'...\n","remote: Enumerating objects: 15, done.\u001b[K\n","remote: Counting objects: 100% (15/15), done.\u001b[K\n","remote: Compressing objects: 100% (11/11), done.\u001b[K\n","remote: Total 9135 (delta 5), reused 11 (delta 4), pack-reused 9120\u001b[K\n","Receiving objects: 100% (9135/9135), 7.07 MiB | 10.44 MiB/s, done.\n","Resolving deltas: 100% (6290/6290), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XSE6CsPUil41","colab_type":"code","outputId":"ca26eb96-afb7-4990-b21c-9729161e47bc","executionInfo":{"status":"ok","timestamp":1589621796995,"user_tz":-180,"elapsed":24953,"user":{"displayName":"Volodymyr Todosiuk","photoUrl":"","userId":"17845359462101600766"}},"colab":{"base_uri":"https://localhost:8080/","height":118}},"source":["%cd yolov3\n","import time\n","import glob\n","import torch\n","import os\n","\n","import argparse\n","from sys import platform\n","\n","from models import *\n","from utils.datasets import *\n","from utils.utils import *\n","\n","from IPython.display import HTML\n","from base64 import b64encode\n","\n","parser = argparse.ArgumentParser()\n","parser.add_argument('--cfg', type=str, default='cfg/yolov3-spp.cfg', help='*.cfg path')\n","parser.add_argument('--names', type=str, default='data/coco.names', help='*.names path')\n","parser.add_argument('--weights', type=str, default='weights/yolov3-spp-ultralytics.pt', help='weights path')\n","\n","parser.add_argument('--img-size', type=int, default=416, help='inference size (pixels)')\n","parser.add_argument('--conf-thres', type=float, default=0.3, help='object confidence threshold')\n","parser.add_argument('--iou-thres', type=float, default=0.6, help='IOU threshold for NMS')\n","\n","\n","parser.add_argument('--device', default='', help='device id (i.e. 0 or 0,1) or cpu')\n","\n","\n","parser.add_argument('--classes', nargs='+', type=int, help='filter by class')\n","parser.add_argument('--agnostic-nms', action='store_true', help='class-agnostic NMS')\n","opt = parser.parse_args(args = [])\n","\n","weights = opt.weights\n","img_size =  opt.img_size\n","\n","# Initialize\n","device = torch_utils.select_device(device='cpu' if ONNX_EXPORT else opt.device)\n","\n","# Initialize model\n","model = Darknet(opt.cfg, img_size)\n","\n","# Load weights\n","attempt_download(weights)\n","if weights.endswith('.pt'):  # pytorch format\n","    model.load_state_dict(torch.load(weights, map_location=device)['model'])\n","else:  # darknet format\n","    load_darknet_weights(model, weights)\n","\n","model.to(device).eval();\n","\n","# Get names and colors\n","names = load_classes(opt.names)\n","colors = [[random.randint(0, 255) for _ in range(3)] for _ in range(len(names))]\n","\n","%cd .. \n","\n","def predict_one_video(path_video, output_dir = 'output'): \n","\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    cap  = cv2.VideoCapture(path_video)\n","    _, img0 = cap.read()\n","\n","    save_path = os.path.join(output_dir, os.path.split(path_video)[-1]) \n","    fps = cap.get(cv2.CAP_PROP_FPS)\n","    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","    vid_writer = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'MP4V'), fps, (w, h))\n","\n","    while img0 is not None: \n","\n","        # Padded resize\n","        img = letterbox(img0, new_shape=opt.img_size)[0]\n","\n","        # Convert\n","        img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3xHxW\n","        img = np.ascontiguousarray(img)\n","\n","        img = torch.from_numpy(img).to(device)\n","        img = img.float()  # uint8 to fp16/32\n","        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n","        if img.ndimension() == 3:\n","            img = img.unsqueeze(0)\n","\n","        pred = model(img)[0]\n","        # Apply NMS\n","        pred = non_max_suppression(pred, opt.conf_thres, opt.iou_thres, classes=opt.classes, agnostic=opt.agnostic_nms)\n","\n","        # Process detections\n","        for i, det in enumerate(pred):  # detections per image\n","            im0 = img0 ##### Ganti im0s menjadi img0\n","\n","            if det is not None and len(det):\n","                # Rescale boxes from img_size to im0 size\n","                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n","\n","                # Write results\n","                for *xyxy, conf, cls in det:\n","                    label = '%s %.2f' % (names[int(cls)], conf)\n","                    plot_one_box(xyxy, im0, label=label, color=colors[int(cls)])\n","\n","        vid_writer.write(im0)\n","        _, img0 = cap.read()\n","\n","    vid_writer.release()\n","\n","    return save_path"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/yolov3\n","Using CUDA device0 _CudaDeviceProperties(name='Tesla T4', total_memory=15079MB)\n","\n","Model Summary: 225 layers, 6.29987e+07 parameters, 6.29987e+07 gradients\n","Downloading https://drive.google.com/uc?export=download&id=1UcR-zVoMs7DH5dj3N1bswkiQTA4dmKF4 as weights/yolov3-spp-ultralytics.pt... Done (3.8s)\n","/content\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UIDQjTkqldCp","colab_type":"code","outputId":"95864333-0f0a-40a1-bfb2-0a9565e39ef3","executionInfo":{"status":"ok","timestamp":1589621802773,"user_tz":-180,"elapsed":30717,"user":{"displayName":"Volodymyr Todosiuk","photoUrl":"","userId":"17845359462101600766"}},"colab":{"base_uri":"https://localhost:8080/","height":134}},"source":["!git clone https://github.com/vindruid/yolov3-in-colab.git\n","!cp -r \"yolov3-in-colab\"/input_video/* ./input_video/"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Cloning into 'yolov3-in-colab'...\n","remote: Enumerating objects: 56, done.\u001b[K\n","remote: Counting objects:   1% (1/56)\u001b[K\rremote: Counting objects:   3% (2/56)\u001b[K\rremote: Counting objects:   5% (3/56)\u001b[K\rremote: Counting objects:   7% (4/56)\u001b[K\rremote: Counting objects:   8% (5/56)\u001b[K\rremote: Counting objects:  10% (6/56)\u001b[K\rremote: Counting objects:  12% (7/56)\u001b[K\rremote: Counting objects:  14% (8/56)\u001b[K\rremote: Counting objects:  16% (9/56)\u001b[K\rremote: Counting objects:  17% (10/56)\u001b[K\rremote: Counting objects:  19% (11/56)\u001b[K\rremote: Counting objects:  21% (12/56)\u001b[K\rremote: Counting objects:  23% (13/56)\u001b[K\rremote: Counting objects:  25% (14/56)\u001b[K\rremote: Counting objects:  26% (15/56)\u001b[K\rremote: Counting objects:  28% (16/56)\u001b[K\rremote: Counting objects:  30% (17/56)\u001b[K\rremote: Counting objects:  32% (18/56)\u001b[K\rremote: Counting objects:  33% (19/56)\u001b[K\rremote: Counting objects:  35% (20/56)\u001b[K\rremote: Counting objects:  37% (21/56)\u001b[K\rremote: Counting objects:  39% (22/56)\u001b[K\rremote: Counting objects:  41% (23/56)\u001b[K\rremote: Counting objects:  42% (24/56)\u001b[K\rremote: Counting objects:  44% (25/56)\u001b[K\rremote: Counting objects:  46% (26/56)\u001b[K\rremote: Counting objects:  48% (27/56)\u001b[K\rremote: Counting objects:  50% (28/56)\u001b[K\rremote: Counting objects:  51% (29/56)\u001b[K\rremote: Counting objects:  53% (30/56)\u001b[K\rremote: Counting objects:  55% (31/56)\u001b[K\rremote: Counting objects:  57% (32/56)\u001b[K\rremote: Counting objects:  58% (33/56)\u001b[K\rremote: Counting objects:  60% (34/56)\u001b[K\rremote: Counting objects:  62% (35/56)\u001b[K\rremote: Counting objects:  64% (36/56)\u001b[K\rremote: Counting objects:  66% (37/56)\u001b[K\rremote: Counting objects:  67% (38/56)\u001b[K\rremote: Counting objects:  69% (39/56)\u001b[K\rremote: Counting objects:  71% (40/56)\u001b[K\rremote: Counting objects:  73% (41/56)\u001b[K\rremote: Counting objects:  75% (42/56)\u001b[K\rremote: Counting objects:  76% (43/56)\u001b[K\rremote: Counting objects:  78% (44/56)\u001b[K\rremote: Counting objects:  80% (45/56)\u001b[K\rremote: Counting objects:  82% (46/56)\u001b[K\rremote: Counting objects:  83% (47/56)\u001b[K\rremote: Counting objects:  85% (48/56)\u001b[K\rremote: Counting objects:  87% (49/56)\u001b[K\rremote: Counting objects:  89% (50/56)\u001b[K\rremote: Counting objects:  91% (51/56)\u001b[K\rremote: Counting objects:  92% (52/56)\u001b[K\rremote: Counting objects:  94% (53/56)\u001b[K\rremote: Counting objects:  96% (54/56)\u001b[K\rremote: Counting objects:  98% (55/56)\u001b[K\rremote: Counting objects: 100% (56/56)\u001b[K\rremote: Counting objects: 100% (56/56), done.\u001b[K\n","remote: Compressing objects: 100% (55/55), done.\u001b[K\n","remote: Total 56 (delta 27), reused 0 (delta 0), pack-reused 0\u001b[K\n","Unpacking objects: 100% (56/56), done.\n","cp: target './input_video/' is not a directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8aAa6E_dllMd","colab_type":"code","colab":{}},"source":["!mkdir -p input_video\n","!mkdir -p output_compressed"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y6PbniXimZ58","colab_type":"code","outputId":"767f5c19-fb15-4204-ad7f-f9e718d3dc7c","executionInfo":{"status":"ok","timestamp":1589621840036,"user_tz":-180,"elapsed":67954,"user":{"displayName":"Volodymyr Todosiuk","photoUrl":"","userId":"17845359462101600766"}},"colab":{"base_uri":"https://localhost:8080/","height":246,"output_embedded_package_id":"1O3fv8u7eVOfS7OiJO3czzu7yUyOCRzd8"}},"source":["path_video = os.path.join(\"/content/yolov3-in-colab/input_video\",\"opera_house.mp4\")\n","save_path = predict_one_video(path_video)\n","\n","# compress video\n","compressed_path = os.path.join(\"output_compressed\", os.path.split(save_path)[-1])\n","os.system(f\"ffmpeg -i {save_path} -vcodec libx264 {compressed_path}\")\n","\n","# Show video\n","mp4 = open(compressed_path,'rb').read()\n","data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","HTML(\"\"\"\n","<video width=400 controls>\n","      <source src=\"%s\" type=\"video/mp4\">\n","</video>\n","\"\"\" % data_url)"],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}